---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<div id="main" role="main">
<div class="sidebar sticky">
<div itemscope="" itemtype="http://schema.org/Person">
<div class="author__avatar">
<img alt="Ritika Lamba" class="author__avatar" src="./Profile_Pic.png"/>
</div>
<div class="author__content">
<h3 class="author__name">Ritika Lamba</h3>
<p class="author__bio">MS Student <br/> Case Western Reserve University (CWRU)</p>
</div>
<div class="author__urls-wrapper">
<button class="btn btn--inverse">Follow</button>
<ul class="author__urls social-icons">
<li><a href="https://www.linkedin.com/in/ritika-lamba"><i class="fab fa-fw fa-linkedin"></i> LinkedIn</a></li>
<li><a href="mailto:ritikalamba@hotmail.com"><i aria-hidden="true" class="fas fa-fw fa-envelope"></i> Email</a></li>
</ul>
</div>
</div>
</div>
<div class="archive">
<h1 id="working-papers-submissions">Working Papers &amp; Submissions</h1>
<ol>
<li>
    **Nexus Companion: Emotion-Labeled Dataset for Empathetic LLMs** (EMNLP Submission)  <br>
    Lead researcher for NexusCompanion, a scalable benchmark for multi-label emotion classification in LLMs.  Curated 100K Reddit conversations labeled using Plutchik's Emotion Model for emotional alignment.  Fine-tuned models with Hugging Face, LoRA, and GPT-4; optimized for inference efficiency and fairness.  Collaborating with Dr. Sumon Biswas and Dr. Max Han.  Submitted to EMNLP 2025. 
</br></li>
<li>
    **Advancements in Counterfactual Explainability with GNNs** <br/>
    Developing dynamic graph neural network methods for counterfactual explanation in LLMs and deep models.  Focus on symbolic interpretability, static analysis, and causal graph modeling.  Advisor: Dr. Jing Ma. 
</li>
<li>
    **Region-Specific LLMs with Fairness-Aware LORA Optimization** <br/>
    Designed fine-tuning techniques for bias mitigation in LLMs across dialects and regional language variants.  Benchmarked fairness with contrastive prompts and symbolic consistency checks. 
</li>
<li>
    **Trustworthy AI and Formal Fairness Research** <br/>
    Contributed to formal fairness testing pipelines for ML models.  Surveyed 75+ papers across symbolic, formal, and empirical fairness auditing frameworks. 
</li>
</ol>
<script src="https://rxl895.github.io/assets/js/main.min.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>
</div></div>
